{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy as gp\n",
    "import datetime\n",
    "import os\n",
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the path to the data\n",
    "path = './datasets/data_for_mvp/'\n",
    "\n",
    "# creating a dataset list for all datasets\n",
    "files = [file for file in os.listdir(path) if 'txt' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading each dataset to each dataframe\n",
    "agency = pd.read_csv(path+files[0])\n",
    "dates = pd.read_csv(path+files[1])\n",
    "stop_times = pd.read_csv(path+files[2])\n",
    "frequencies = pd.read_csv(path+files[3])\n",
    "shapes = pd.read_csv(path+files[4])\n",
    "trips = pd.read_csv(path+files[5])\n",
    "stops = pd.read_csv(path+files[6])\n",
    "calendar = pd.read_csv(path+files[7])\n",
    "routes = pd.read_csv(path+files[8])\n",
    "\n",
    "# Creating a dictionary w/all datasets:\n",
    "all_ds = {\"agency\": agency, \n",
    "          \"dates\": dates, \n",
    "          \"stop times\": stop_times, \n",
    "          \"frequencies\": frequencies, \n",
    "          \"shapes\": shapes, \n",
    "          \"trips\": trips, \n",
    "          \"stops\": stops, \n",
    "          \"calendar\": calendar, \n",
    "          \"routes\": routes}\n",
    "\n",
    "# Creating a quick check acces to the dataset names for visual reference check\n",
    "access = f\"Dict name: all_ds. \\n\\nKeys: {all_ds.keys()}, \\nDataSets: {len(all_ds)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict name: all_ds. \n",
      "\n",
      "Keys: dict_keys(['agency', 'dates', 'stop times', 'frequencies', 'shapes', 'trips', 'stops', 'calendar', 'routes']), \n",
      "DataSets: 9\n"
     ]
    }
   ],
   "source": [
    "# checking how prevalent missing values are in our data (for each dataset)\n",
    "\n",
    "# defining a function to check null values:\n",
    "def null_cols(ds):\n",
    "    \"\"\"check whether the value in each field is missing (null) and return either \n",
    "    True or False for each field, totaling up the number of True values by column. \"\"\"\n",
    "    return ds.isnull().sum()\n",
    "\n",
    "# applying the filter to each dataset\n",
    "agency_null_cols = null_cols(agency)\n",
    "dates_null_cols = null_cols(dates)\n",
    "stop_times_null_cols = null_cols(stop_times)\n",
    "frequencies_null_cols = null_cols(frequencies)\n",
    "shapes_null_cols = null_cols(shapes)\n",
    "trips_null_cols = null_cols(trips)\n",
    "stops_null_cols = null_cols(stops)\n",
    "calendar_null_cols = null_cols(calendar)\n",
    "routes_null_cols = null_cols(routes)\n",
    "\n",
    "# Adding a condition that will filter the data and show us only columns where the number \n",
    "# of null values were greater than zero for each dataset. Greater than zero because, in \n",
    "# this case, when a column has a null value, all the column has null values:\n",
    "\n",
    "# 'agency_phone' = 1\n",
    "agency_null_cols[agency_null_cols > 0] \n",
    "\n",
    "# dates['exception_type'].value_counts() == 1 \n",
    "dates_null_cols[dates_null_cols > 0]  \n",
    "\n",
    "# ['stop_headsign', 'pickup_type', 'drop_off_type', shape_dist_traveled] = 1842 (All \n",
    "# entries)\n",
    "stop_times_null_cols[stop_times_null_cols > 0] \n",
    "\n",
    "# frequencies['exact_times'].value_counts() == 0\n",
    "frequencies_null_cols[frequencies_null_cols > 0] \n",
    "\n",
    "# 'shape_dist_traveled' = 182 (All entries)\n",
    "shapes_null_cols[shapes_null_cols > 0] \n",
    "\n",
    "# ['trip_headsign', 'direction_id', 'block_id'] = 132 (All entries)\n",
    "trips_null_cols[trips_null_cols > 0]\n",
    "\n",
    "# ['stop_code', 'stop_desc', 'zone_id', 'stop_url', 'location_type', 'parent_station'] = 49 (All entries)\n",
    "stops_null_cols[stops_null_cols > 0]\n",
    "\n",
    "# nothing to declare\n",
    "calendar_null_cols[calendar_null_cols > 0]\n",
    "\n",
    "# ['route_short_name', 'route_desc', 'route_url', 'route_color', 'route_text_color'] = 10 \n",
    "# (All entries)\n",
    "routes_null_cols[routes_null_cols > 0]\n",
    "\n",
    "print(access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict name: all_ds. \n",
      "\n",
      "Keys: dict_keys(['agency', 'dates', 'stop times', 'frequencies', 'shapes', 'trips', 'stops', 'calendar', 'routes']), \n",
      "DataSets: 9\n"
     ]
    }
   ],
   "source": [
    "# Judgement call: droping information that we don't think it's going to be very useful \n",
    "# to our analysis (removing those columns from your datasets) with the drop method.\n",
    "# We will add these column names to a list, and then we will pass those columns to the \n",
    "# drop method and indicate that we want columns (not rows) dropped by setting the axis \n",
    "# parameter to 1.\n",
    "\n",
    "# defining a function to create a list:\n",
    "def drop_cols(bad_cols):\n",
    "    \"\"\"Adding col names to a list to be droped; in this case as long as the col has a \n",
    "    single null value in it, since, in this case, if it has one, their all null.\"\"\"\n",
    "    \n",
    "    return list(bad_cols[bad_cols > 0].index)\n",
    "\n",
    "# applying the function to each ds\n",
    "agency_drop_cols = drop_cols(agency_null_cols) # drops 'agency_phone'\n",
    "dates_drop_cols = drop_cols(dates_null_cols) # this one has no cols to drop\n",
    "stop_times_drop_cols = drop_cols(stop_times_null_cols) # drops ['stop_headsign', \n",
    "# 'pickup_type', 'drop_off_type', shape_dist_traveled]\n",
    "frequencies_drop_cols = drop_cols(frequencies_null_cols) # this one has no cols to drop\n",
    "shapes_drop_cols = drop_cols(shapes_null_cols)\n",
    "trips_drop_cols = drop_cols(trips_null_cols)\n",
    "stops_drop_cols = drop_cols(stops_null_cols)\n",
    "calendar_drop_cols = drop_cols(calendar_null_cols) # this one has no cols to drop\n",
    "routes_drop_cols = drop_cols(routes_null_cols)\n",
    "\n",
    "# Passing those columns to the drop method and indicate that we want columns (not rows) \n",
    "# dropped by setting the axis parameter to 1:\n",
    "agency = agency.drop(agency_drop_cols, axis = 1)\n",
    "dates = dates.drop(dates_drop_cols, axis = 1)\n",
    "stop_times = stop_times.drop(stop_times_drop_cols, axis = 1)\n",
    "frequencies = frequencies.drop(frequencies_drop_cols, axis = 1)\n",
    "shapes = shapes.drop(shapes_drop_cols, axis = 1)\n",
    "trips = trips.drop(trips_drop_cols, axis = 1)\n",
    "stops = stops.drop(stops_drop_cols, axis = 1)\n",
    "calendar = calendar.drop(calendar_drop_cols, axis = 1)\n",
    "routes = routes.drop(routes_drop_cols, axis = 1)\n",
    "\n",
    "# this should've left us w/no cols with null values in the datasets\n",
    "print(access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_id</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25816292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25816294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25816296</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25816298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25816300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>25816345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>25816349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>25816347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>25816353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>25816351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20190916</td>\n",
       "      <td>20290916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
       "0      25816292       1        1          1         1       1         0   \n",
       "1      25816294       1        1          1         1       1         0   \n",
       "2      25816296       1        1          1         1       1         0   \n",
       "3      25816298       1        1          1         1       1         0   \n",
       "4      25816300       1        1          1         1       1         0   \n",
       "..          ...     ...      ...        ...       ...     ...       ...   \n",
       "127    25816345       0        0          0         0       0         0   \n",
       "128    25816349       0        0          0         0       0         0   \n",
       "129    25816347       0        0          0         0       0         0   \n",
       "130    25816353       0        0          0         0       0         0   \n",
       "131    25816351       0        0          0         0       0         0   \n",
       "\n",
       "     sunday  start_date  end_date  \n",
       "0         0    20190916  20290916  \n",
       "1         0    20190916  20290916  \n",
       "2         0    20190916  20290916  \n",
       "3         0    20190916  20290916  \n",
       "4         0    20190916  20290916  \n",
       "..      ...         ...       ...  \n",
       "127       1    20190916  20290916  \n",
       "128       1    20190916  20290916  \n",
       "129       1    20190916  20290916  \n",
       "130       1    20190916  20290916  \n",
       "131       1    20190916  20290916  \n",
       "\n",
       "[132 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# TRATAR O ROUTES\\ncolumns_to_keep = [\\'route_id\\', \\'route_long_name\\']\\nD_routes = routes[columns_to_keep]\\n#D_routes[\\'line\\'] = D_routes[D_routes[\\'route_long_name\\'].split(\\' - \\')]#.split(\" - \")\\nstringlist = [v for v in D_routes[\\'route_long_name\\']]\\nstringlist_doubled = [x.split(\\' - \\') for x in stringlist]\\nstringlist_doubled\\nD_routes[\\'line\\'] = [y[0] for y in stringlist_doubled]\\nD_routes[\\'destination\\'] = [y[1] for y in stringlist_doubled]\\n\\n\\nD_routes.rename(columns={\"route_id\": \"destination_id\"}, inplace = True)\\n\\nD_routes\\n# string.split(\\' - \\')\\n\\n# TRATAR O TRIPS\\ncolumns_to_keep = [\\'trip_id\\', \\'shape_id\\']\\nD_trips = D_trips[columns_to_keep]\\n#D_trips[\\'trip_id\\'] = D_trips[\\'ID_OF_STUFF\\']\\n\\n##\\nD_trips.rename(columns={\"shape_id\": \"destination_id\"}, inplace = True)\\n\\n# TRATAR O CALENDAR\\ncalendar = calendar.rename(columns={\"service_id\": \"trip_id\"})\\ncalendar\\n\\n## Fazer um merge da coluna weekday baseado no trip_id por oposicao ao datetime parsing\\n\\n# TRATAR O DATES\\ncalendar_dates = calendar_dates[[\\'service_id\\', \\'date\\']]\\n\\ncalendar_dates[\\'year\\'] = [str(v)[0:4] for v in calendar_dates[\\'date\\']]\\ncalendar_dates[\\'month\\'] = [str(v)[4:6] for v in calendar_dates[\\'date\\']]\\ncalendar_dates[\\'day\\'] = [str(v)[6:8] for v in calendar_dates[\\'date\\']]\\ncalendar_dates[\\'pdate\\'] = calendar_dates[\\'year\\'] + \\'-\\' + calendar_dates[\\'month\\'] + \\'-\\' + calendar_dates[\\'day\\']\\ncalendar_dates[\\'datetime\\'] = pd.to_datetime(calendar_dates[\\'pdate\\'])\\ncalendar_dates.drop([\"year\", \"month\", \"day\", \"pdate\", \"date\"], axis = 1, inplace = True)\\ncalendar_dates.rename(columns={\"service_id\": \"trip_id\"}, inplace = True)\\n\\ncalendar_dates'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# TRATAR O ROUTES\n",
    "columns_to_keep = ['route_id', 'route_long_name']\n",
    "D_routes = routes[columns_to_keep]\n",
    "#D_routes['line'] = D_routes[D_routes['route_long_name'].split(' - ')]#.split(\" - \")\n",
    "stringlist = [v for v in D_routes['route_long_name']]\n",
    "stringlist_doubled = [x.split(' - ') for x in stringlist]\n",
    "stringlist_doubled\n",
    "D_routes['line'] = [y[0] for y in stringlist_doubled]\n",
    "D_routes['destination'] = [y[1] for y in stringlist_doubled]\n",
    "\n",
    "\n",
    "D_routes.rename(columns={\"route_id\": \"destination_id\"}, inplace = True)\n",
    "\n",
    "D_routes\n",
    "# string.split(' - ')\n",
    "\n",
    "# TRATAR O TRIPS\n",
    "columns_to_keep = ['trip_id', 'shape_id']\n",
    "D_trips = D_trips[columns_to_keep]\n",
    "#D_trips['trip_id'] = D_trips['ID_OF_STUFF']\n",
    "\n",
    "##\n",
    "D_trips.rename(columns={\"shape_id\": \"destination_id\"}, inplace = True)\n",
    "\n",
    "# TRATAR O CALENDAR\n",
    "calendar = calendar.rename(columns={\"service_id\": \"trip_id\"})\n",
    "calendar\n",
    "\n",
    "## Fazer um merge da coluna weekday baseado no trip_id por oposicao ao datetime parsing\n",
    "\n",
    "# TRATAR O DATES\n",
    "calendar_dates = calendar_dates[['service_id', 'date']]\n",
    "\n",
    "calendar_dates['year'] = [str(v)[0:4] for v in calendar_dates['date']]\n",
    "calendar_dates['month'] = [str(v)[4:6] for v in calendar_dates['date']]\n",
    "calendar_dates['day'] = [str(v)[6:8] for v in calendar_dates['date']]\n",
    "calendar_dates['pdate'] = calendar_dates['year'] + '-' + calendar_dates['month'] + '-' + calendar_dates['day']\n",
    "calendar_dates['datetime'] = pd.to_datetime(calendar_dates['pdate'])\n",
    "calendar_dates.drop([\"year\", \"month\", \"day\", \"pdate\", \"date\"], axis = 1, inplace = True)\n",
    "calendar_dates.rename(columns={\"service_id\": \"trip_id\"}, inplace = True)\n",
    "\n",
    "calendar_dates\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALAMEDA',\n",
       " 'ALVALADE',\n",
       " 'ANJOS',\n",
       " 'AREEIRO',\n",
       " 'BAIXA-CHIADO',\n",
       " 'CAIS DO SODRE',\n",
       " 'CAMPO GRANDE',\n",
       " 'INTENDENTE',\n",
       " 'MARTIM MONIZ',\n",
       " 'ROMA',\n",
       " 'TELHEIRAS']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estacoes = stops['stop_name']\n",
    "\n",
    "verde = ['ALAMEDA', \n",
    "         'ALVALADE', \n",
    "         'ANJOS', \n",
    "         'AREEIRO', \n",
    "         'BAIXA-CHIADO', \n",
    "         'CAIS DO SODRE', \n",
    "         'CAMPO GRANDE', \n",
    "         'INTENDENTE', \n",
    "         'MARTIM MONIZ', \n",
    "         'ROMA',  \n",
    "         'TELHEIRAS']\n",
    "\n",
    "azul = ['ALFORNELOS', \n",
    "        'ALTO DOS MOINHOS', \n",
    "        'AMADORA ESTE', \n",
    "        'AVENIDA', \n",
    "        'BAIXA-CHIADO', \n",
    "        'CARNIDE', \n",
    "        'COLÉGIO MILITAR-LUZ', \n",
    "        'JARDIM ZOOLÓGICO', \n",
    "        'LARANJEIRAS',\n",
    "        'MARQUÊS DE POMBAL', \n",
    "        'PARQUE', \n",
    "        'PONTINHA', \n",
    "        'PRAÇA DE ESPANHA', \n",
    "        'REBOLEIRA', \n",
    "        'RESTAURADORES', \n",
    "        'ROSSIO',\n",
    "        'SANTA APOLÓNIA', \n",
    "        'SÃO SEBASTIÃO', \n",
    "        'TERREIRO DO PAÇO']\n",
    "\n",
    "vermelha = ['AEROPORTO', \n",
    "            'ALAMEDA', \n",
    "            'BELA VISTA', \n",
    "            'CABO RUIVO', \n",
    "            'CHELAS', \n",
    "            'ENCARNAÇÃO', \n",
    "            'MOSCAVIDE', \n",
    "            'OLAIAS', \n",
    "            'OLIVAIS', \n",
    "            'ORIENTE', \n",
    "            'SALDANHA', \n",
    "            'SÃO SEBASTIÃO']\n",
    "\n",
    "amarela = ['AMEIXOEIRA', \n",
    "           'CAMPO GRANDE', \n",
    "           'CAMPO PEQUENO', \n",
    "           'CIDADE UNIVERSITÁRIA',\n",
    "           'ENTRECAMPOS', \n",
    "           'LUMIAR', \n",
    "           'MARQUÊS DE POMBAL', \n",
    "           'ODIVELAS', \n",
    "           'PICOAS', \n",
    "           'QUINTA DAS CONCHAS', \n",
    "           'RATO', \n",
    "           'SALDANHA', \n",
    "           'SR. ROUBADO']\n",
    "\n",
    "roxa = ['CAMPO GRANDE',\n",
    "        'CAMPO PEQUENO', \n",
    "        'CIDADE UNIVERSITÁRIA',\n",
    "        'ENTRECAMPOS', \n",
    "        'MARQUÊS DE POMBAL', \n",
    "        'PICOAS', \n",
    "        'RATO', \n",
    "        'SALDANHA']\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
